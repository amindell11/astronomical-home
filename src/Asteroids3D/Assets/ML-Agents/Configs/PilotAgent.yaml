behaviors:
  RLPilot:
    trainer_type: ppo
    
    hyperparameters:
      batch_size: 640
      buffer_size: 10240
      learning_rate: 2.0e-4
      learning_rate_schedule: linear
      beta: 4.0e-3
      beta_schedule: constant
      epsilon: 0.2
      epsilon_schedule: linear
      lambd: 0.95
      num_epoch: 3

    network_settings:
      normalize: false
      hidden_units: 256
      num_layers: 1
      vis_encode_type: simple

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

    max_steps: 5000000
    summary_freq: 20000
    time_horizon: 1280
    keep_checkpoints: 5

environment_parameters:
  arena_size:
    curriculum:
      - name: L0_spatial
        value: 80
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 5 }
      - name: L1_spatial
        value: 60
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 10 }
      - name: L2_spatial
        value: 50
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 15, require_reset: true }
      - name: L3_randomised
        value:
          sampler_type: uniform
          sampler_parameters: { min_value: 40, max_value: 80 }

  asteroid_density:
    curriculum:
      - name: L0_density
        value: 0.2
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 5 }
      - name: L1_density
        value: 0.4
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 10 }
      - name: L2_density
        value: 0.6
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 15, require_reset: true }
      - name: L3_randomised
        value:
          sampler_type: uniform
          sampler_parameters: { min_value: 0.4, max_value: 1.0 }

  bot_difficulty:
    curriculum:
      - name: L0_static_bot
        value: 0.2
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.8, min_lesson_length: 20 }
      - name: L1_mobile_bot
        value: 0.4
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.7, min_lesson_length: 25 }
      - name: L2_guns_only
        value: 0.6
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 30 }
      - name: L3_full_arsenal
        value: 1.0
        completion_criteria: { measure: reward, behavior: RLPilot, threshold: 0.6, min_lesson_length: 30, require_reset: true }
      - name: L4_randomised
        value:
          sampler_type: multirangeuniform
          sampler_parameters:
            intervals: [[0.8, 1.0]]   # mostly hard, occasional relief if you widen intervals
