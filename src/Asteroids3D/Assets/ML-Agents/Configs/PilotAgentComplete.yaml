behaviors:
  RLPilot:
    # Unified PPO configuration that supports both curriculum (phase 1) and self-play (phase 2)
    trainer_type: ppo

    # Hyper-parameters follow prior "PilotAgentSelfPlay_v3" defaults (good for long training)
    hyperparameters:
      batch_size: 1024
      buffer_size: 10240
      learning_rate: 2.0e-4          # Start slightly lower to keep learning stable across phases
      learning_rate_schedule: linear
      beta: 2.0e-3
      beta_schedule: constant
      epsilon: 0.2
      epsilon_schedule: linear
      lambd: 0.95
      num_epoch: 3

    network_settings:
      normalize: false
      hidden_units: 256
      num_layers: 2
      vis_encode_type: simple

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

    # Self-play is enabled for the entire run. During curriculum (phase 1) the agent mostly
    # encounters simple opponents/arena; once the curriculum completes it automatically faces
    # stronger opponents and a more complex arena (arena_variant=1).
    self_play:
      window: 10                        # Number of past policies to keep
      play_against_latest_model_ratio: 0.5  # 50% chance to play against current model
      save_steps: 50000                 # Save policy snapshot every 50k steps
      swap_steps: 10000                 # Change opponent every 10k steps
      team_change: 500000               # Switch which team is learning every 500k steps

    max_steps: 10000000
    summary_freq: 20000
    time_horizon: 2048                  # Longer episodes for richer self-play dynamics
    keep_checkpoints: 5
    checkpoint_interval: 500000

# ---------------------------------------------------------------------------
# Environment parameters â€“ combine curriculum progression (phase 1) with
# eventual transition to competitive self-play (phase 2).
# The new "arena_variant" parameter switches the arena prefab once the
# curriculum is complete (requires ArenaManager prefab-variant support).
# ---------------------------------------------------------------------------
environment_parameters:
  arena_variant:
    curriculum:
      - name: Curriculum-Phase
        completion_criteria:
          measure: reward
          behavior: RLPilot
          min_lesson_length: 50
          threshold: 0.6
        value: 0            # Uses simple training arena prefab (variantId = 0)
      - name: SelfPlay-Phase
        value: 1            # Switches to competitive/self-play arena prefab (variantId = 1)

  arena_size:
    curriculum:
      - name: Lesson-1
        completion_criteria:
          measure: reward
          behavior: RLPilot
          min_lesson_length: 50
          threshold: 0.6
        value: 60
      - name: Lesson-2
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 50
      - name: Lesson-3
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 40
      - name: SelfPlay-Randomized
        sampler_type: uniform
        sampler_parameters:
          min_value: 40
          max_value: 80

  asteroid_density:
    curriculum:
      - name: Lesson-1
        completion_criteria:
          measure: reward
          behavior: RLPilot
          min_lesson_length: 50
          threshold: 0.6
        value: 0.4
      - name: Lesson-2
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 0.6
      - name: Lesson-3
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 0.8
      - name: SelfPlay-Randomized
        sampler_type: uniform
        sampler_parameters:
          min_value: 0.4
          max_value: 0.8

  bot_difficulty:
    curriculum:
      - name: Lesson-1
        completion_criteria:
          measure: reward
          behavior: RLPilot
          min_lesson_length: 50
          threshold: 0.6
        value: 0.4
      - name: Lesson-2
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 0.7
      - name: Lesson-3
        completion_criteria:
          measure: reward
          behavior: RLPilot
          threshold: 0.6
          min_lesson_length: 50
        value: 1.0
      - name: SelfPlay-Stage
        value: 1.0  # Bot difficulty irrelevant; bot replaced by RL opponent once reached 