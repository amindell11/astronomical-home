{
    "name": "root",
    "gauges": {
        "RLPilot.Policy.Entropy.mean": {
            "value": 2.3742270469665527,
            "min": 2.337745428085327,
            "max": 2.4056758880615234,
            "count": 23
        },
        "RLPilot.Policy.Entropy.sum": {
            "value": 65433.6953125,
            "min": 3117.755859375,
            "max": 166431.109375,
            "count": 23
        },
        "RLPilot.Environment.LessonNumber.arena_size.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "RLPilot.Environment.LessonNumber.arena_size.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "RLPilot.Environment.LessonNumber.asteroid_density.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "RLPilot.Environment.LessonNumber.asteroid_density.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "RLPilot.Environment.EpisodeLength.mean": {
            "value": 1029.1304347826087,
            "min": 9.0,
            "max": 1235.825,
            "count": 23
        },
        "RLPilot.Environment.EpisodeLength.sum": {
            "value": 23670.0,
            "min": 576.0,
            "max": 49433.0,
            "count": 23
        },
        "RLPilot.Self-play.ELO.mean": {
            "value": 834.595809697316,
            "min": 834.595809697316,
            "max": 899.7473806339731,
            "count": 23
        },
        "RLPilot.Self-play.ELO.sum": {
            "value": 11684.341335762423,
            "min": 11005.943949103827,
            "max": 119940.03735990894,
            "count": 23
        },
        "RLPilot.Step.mean": {
            "value": 1939706.0,
            "min": 1499995.0,
            "max": 1939706.0,
            "count": 23
        },
        "RLPilot.Step.sum": {
            "value": 1939706.0,
            "min": 1499995.0,
            "max": 1939706.0,
            "count": 23
        },
        "RLPilot.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.03556216508150101,
            "min": -0.08680907636880875,
            "max": 0.03468384966254234,
            "count": 23
        },
        "RLPilot.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.8890541195869446,
            "min": -5.322409629821777,
            "max": 1.0058315992355347,
            "count": 23
        },
        "RLPilot.Environment.CumulativeReward.mean": {
            "value": -0.9553572173629489,
            "min": -0.9553572173629489,
            "max": 0.3056040660098747,
            "count": 23
        },
        "RLPilot.Environment.CumulativeReward.sum": {
            "value": -13.375001043081284,
            "min": -61.72970767051447,
            "max": 8.251309782266617,
            "count": 23
        },
        "RLPilot.Policy.ExtrinsicReward.mean": {
            "value": -0.9553572173629489,
            "min": -0.9553572173629489,
            "max": 0.3056040660098747,
            "count": 23
        },
        "RLPilot.Policy.ExtrinsicReward.sum": {
            "value": -13.375001043081284,
            "min": -61.72970767051447,
            "max": 8.251309782266617,
            "count": 23
        },
        "RLPilot.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 23
        },
        "RLPilot.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 23
        },
        "RLPilot.Losses.PolicyLoss.mean": {
            "value": 0.029190482104483332,
            "min": 0.018467236939150925,
            "max": 0.029190482104483332,
            "count": 22
        },
        "RLPilot.Losses.PolicyLoss.sum": {
            "value": 0.029190482104483332,
            "min": 0.019200167846671928,
            "max": 0.05464467061476281,
            "count": 22
        },
        "RLPilot.Losses.ValueLoss.mean": {
            "value": 0.021777729379634063,
            "min": 0.021777729379634063,
            "max": 0.08617143779993057,
            "count": 22
        },
        "RLPilot.Losses.ValueLoss.sum": {
            "value": 0.021777729379634063,
            "min": 0.021777729379634063,
            "max": 0.09168399347726142,
            "count": 22
        },
        "RLPilot.Policy.LearningRate.mean": {
            "value": 0.00024211135929622004,
            "min": 0.00024211135929622004,
            "max": 0.00025469467510177995,
            "count": 22
        },
        "RLPilot.Policy.LearningRate.sum": {
            "value": 0.00024211135929622004,
            "min": 0.00024211135929622004,
            "max": 0.0005083389605536901,
            "count": 22
        },
        "RLPilot.Policy.Epsilon.mean": {
            "value": 0.18070378,
            "min": 0.18070378,
            "max": 0.18489822,
            "count": 22
        },
        "RLPilot.Policy.Epsilon.sum": {
            "value": 0.18070378,
            "min": 0.18070378,
            "max": 0.36944631000000006,
            "count": 22
        },
        "RLPilot.Policy.Beta.mean": {
            "value": 0.0020000000000000005,
            "min": 0.002,
            "max": 0.0020000000000000005,
            "count": 22
        },
        "RLPilot.Policy.Beta.sum": {
            "value": 0.0020000000000000005,
            "min": 0.002,
            "max": 0.004000000000000001,
            "count": 22
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1750954151",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\desir\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn ./Configs/PilotAgentSelfPlay.yaml --run-id=SelfPlay_v2 --env=../../TrainingBuild/LightingTest.exe --no-graphics --quality-level=0 --num-envs=8 --time-scale=3 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1750956511"
    },
    "total": 2360.562607599997,
    "count": 1,
    "self": 5.364322899993567,
    "children": {
        "run_training.setup": {
            "total": 1.9219856000054278,
            "count": 1,
            "self": 1.9219856000054278
        },
        "TrainerController.start_learning": {
            "total": 2353.276299099998,
            "count": 1,
            "self": 3.002086499320285,
            "children": {
                "TrainerController._reset_env": {
                    "total": 40.75981340000726,
                    "count": 2,
                    "self": 40.75981340000726
                },
                "TrainerController.advance": {
                    "total": 2309.065942800662,
                    "count": 8860,
                    "self": 3.159213900951727,
                    "children": {
                        "env_step": {
                            "total": 1619.3065887997654,
                            "count": 8860,
                            "self": 410.90879230012797,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1205.9617465995689,
                                    "count": 41279,
                                    "self": 44.675195099458506,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1161.2865515001104,
                                            "count": 80993,
                                            "self": 1161.2865515001104
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.4360499000686104,
                                    "count": 8859,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 18488.55958650082,
                                            "count": 41267,
                                            "is_parallel": true,
                                            "self": 14400.153711101011,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.013032100010605063,
                                                    "count": 9,
                                                    "is_parallel": true,
                                                    "self": 0.003750800038687885,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.009281299971917178,
                                                            "count": 54,
                                                            "is_parallel": true,
                                                            "self": 0.009281299971917178
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4088.3928432998,
                                                    "count": 41267,
                                                    "is_parallel": true,
                                                    "self": 22.657478101456945,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 21.969837699805794,
                                                            "count": 41267,
                                                            "is_parallel": true,
                                                            "self": 21.969837699805794
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3967.844815599179,
                                                            "count": 41267,
                                                            "is_parallel": true,
                                                            "self": 3967.844815599179
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 75.92071189935814,
                                                            "count": 81689,
                                                            "is_parallel": true,
                                                            "self": 26.831380697040004,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 49.089331202318135,
                                                                    "count": 490134,
                                                                    "is_parallel": true,
                                                                    "self": 49.089331202318135
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 686.6001400999448,
                            "count": 8859,
                            "self": 8.737238100045943,
                            "children": {
                                "process_trajectory": {
                                    "total": 147.77277339992725,
                                    "count": 8859,
                                    "self": 147.29155029993126,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.48122309999598656,
                                            "count": 1,
                                            "self": 0.48122309999598656
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 530.0901285999716,
                                    "count": 41,
                                    "self": 334.7335022000407,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 195.35662639993097,
                                            "count": 1278,
                                            "self": 195.35662639993097
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.1000017770566046e-06,
                    "count": 1,
                    "self": 3.1000017770566046e-06
                },
                "TrainerController._save_models": {
                    "total": 0.44845330000680406,
                    "count": 1,
                    "self": 0.045946900005219504,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.40250640000158455,
                            "count": 1,
                            "self": 0.40250640000158455
                        }
                    }
                }
            }
        }
    }
}