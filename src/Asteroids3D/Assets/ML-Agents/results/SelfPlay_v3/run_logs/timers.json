{
    "name": "root",
    "gauges": {
        "RLPilot.Policy.Entropy.mean": {
            "value": 2.2911601066589355,
            "min": 2.286130905151367,
            "max": 2.356017827987671,
            "count": 31
        },
        "RLPilot.Policy.Entropy.sum": {
            "value": 84965.3828125,
            "min": 11774.9912109375,
            "max": 257787.734375,
            "count": 31
        },
        "RLPilot.Arena.KillRate.mean": {
            "value": 0.5917698939641317,
            "min": 0.290322583529257,
            "max": 0.6817263689908114,
            "count": 31
        },
        "RLPilot.Arena.KillRate.sum": {
            "value": 21.30371618270874,
            "min": 4.476190567016602,
            "max": 54.31895154714584,
            "count": 31
        },
        "RLPilot.Environment.LessonNumber.arena_size.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 31
        },
        "RLPilot.Environment.LessonNumber.arena_size.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 31
        },
        "RLPilot.Environment.LessonNumber.asteroid_density.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 31
        },
        "RLPilot.Environment.LessonNumber.asteroid_density.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 31
        },
        "RLPilot.Environment.EpisodeLength.mean": {
            "value": 1201.138888888889,
            "min": 95.58682634730539,
            "max": 1756.4444444444443,
            "count": 31
        },
        "RLPilot.Environment.EpisodeLength.sum": {
            "value": 43241.0,
            "min": 5598.0,
            "max": 46238.0,
            "count": 31
        },
        "RLPilot.Self-play.ELO.mean": {
            "value": 980.4776473968044,
            "min": 980.4776473968044,
            "max": 1035.1955535496381,
            "count": 31
        },
        "RLPilot.Self-play.ELO.sum": {
            "value": 17648.59765314248,
            "min": 4007.165720012302,
            "max": 170807.2663356903,
            "count": 31
        },
        "RLPilot.Step.mean": {
            "value": 1158805.0,
            "min": 559825.0,
            "max": 1158805.0,
            "count": 31
        },
        "RLPilot.Step.sum": {
            "value": 1158805.0,
            "min": 559825.0,
            "max": 1158805.0,
            "count": 31
        },
        "RLPilot.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.028985708951950073,
            "min": -0.061955731362104416,
            "max": -0.004727758467197418,
            "count": 31
        },
        "RLPilot.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.5217427611351013,
            "min": -6.724542617797852,
            "max": -0.1262722760438919,
            "count": 31
        },
        "RLPilot.Environment.CumulativeReward.mean": {
            "value": 0.13677792251110077,
            "min": -1.4858281135559082,
            "max": 0.4038524106144905,
            "count": 31
        },
        "RLPilot.Environment.CumulativeReward.sum": {
            "value": 2.462002605199814,
            "min": -16.517518043518066,
            "max": 4.846228927373886,
            "count": 31
        },
        "RLPilot.Policy.ExtrinsicReward.mean": {
            "value": 0.13677792251110077,
            "min": -1.4858281135559082,
            "max": 0.4038524106144905,
            "count": 31
        },
        "RLPilot.Policy.ExtrinsicReward.sum": {
            "value": 2.462002605199814,
            "min": -16.517518043518066,
            "max": 4.846228927373886,
            "count": 31
        },
        "RLPilot.Arena.AvgNormalizedDistance.mean": {
            "value": 0.46697041392326355,
            "min": 0.3851448338140141,
            "max": 0.5997385034958521,
            "count": 31
        },
        "RLPilot.Arena.AvgNormalizedDistance.sum": {
            "value": 16.810934901237488,
            "min": 3.5025689005851746,
            "max": 46.382993906736374,
            "count": 31
        },
        "RLPilot.Arena.DamageDealt_RLShip.mean": {
            "value": 348.10703364540547,
            "min": 96.80720564745201,
            "max": 574.6221879118232,
            "count": 31
        },
        "RLPilot.Arena.DamageDealt_RLShip.sum": {
            "value": 94685.1131515503,
            "min": 17134.151306152344,
            "max": 250845.78495788574,
            "count": 31
        },
        "RLPilot.Arena.DamageDealt_RLShip(1).mean": {
            "value": 344.77083203351054,
            "min": 93.50400390437545,
            "max": 575.0864148347274,
            "count": 31
        },
        "RLPilot.Arena.DamageDealt_RLShip(1).sum": {
            "value": 93088.12464904785,
            "min": 17821.36441040039,
            "max": 259149.23391532898,
            "count": 31
        },
        "RLPilot.Arena.DamageTaken_RLShip(1).mean": {
            "value": 348.10703364540547,
            "min": 96.98090291792347,
            "max": 574.6221879118232,
            "count": 31
        },
        "RLPilot.Arena.DamageTaken_RLShip(1).sum": {
            "value": 94685.1131515503,
            "min": 17134.151306152344,
            "max": 250845.78495788574,
            "count": 31
        },
        "RLPilot.Arena.DamageTaken_RLShip.mean": {
            "value": 344.77083203351054,
            "min": 93.50400390437545,
            "max": 575.4668496173362,
            "count": 31
        },
        "RLPilot.Arena.DamageTaken_RLShip.sum": {
            "value": 93088.12464904785,
            "min": 17821.36441040039,
            "max": 259289.23391532898,
            "count": 31
        },
        "RLPilot.Arena.AvgDamageDealt.mean": {
            "value": 329.53376473320856,
            "min": 92.31547151045366,
            "max": 556.1805556615194,
            "count": 31
        },
        "RLPilot.Arena.AvgDamageDealt.sum": {
            "value": 11863.215530395508,
            "min": 2202.574188232422,
            "max": 32149.808784484863,
            "count": 31
        },
        "RLPilot.Arena.AvgDamageTaken.mean": {
            "value": 329.53376473320856,
            "min": 92.39501696499912,
            "max": 556.362847328186,
            "count": 31
        },
        "RLPilot.Arena.AvgDamageTaken.sum": {
            "value": 11863.215530395508,
            "min": 2202.574188232422,
            "max": 32158.558784484863,
            "count": 31
        },
        "RLPilot.Losses.PolicyLoss.mean": {
            "value": 0.025688372078244964,
            "min": 0.016553223645314575,
            "max": 0.02888541957927924,
            "count": 31
        },
        "RLPilot.Losses.PolicyLoss.sum": {
            "value": 0.05137674415648993,
            "min": 0.016553223645314575,
            "max": 0.05481399155052548,
            "count": 31
        },
        "RLPilot.Losses.ValueLoss.mean": {
            "value": 0.024172958390166362,
            "min": 0.017704703208679954,
            "max": 0.0729765218993028,
            "count": 31
        },
        "RLPilot.Losses.ValueLoss.sum": {
            "value": 0.048345916780332725,
            "min": 0.022261212213021336,
            "max": 0.0897851056108872,
            "count": 31
        },
        "RLPilot.Policy.LearningRate.mean": {
            "value": 0.00017701121149440004,
            "min": 0.00017701121149440004,
            "max": 0.00018890274554863004,
            "count": 31
        },
        "RLPilot.Policy.LearningRate.sum": {
            "value": 0.0003540224229888001,
            "min": 0.00017781351109325,
            "max": 0.0003771753314123401,
            "count": 31
        },
        "RLPilot.Policy.Epsilon.mean": {
            "value": 0.18850560000000002,
            "min": 0.18850560000000002,
            "max": 0.19445137000000007,
            "count": 31
        },
        "RLPilot.Policy.Epsilon.sum": {
            "value": 0.37701120000000005,
            "min": 0.18890675000000004,
            "max": 0.38858766,
            "count": 31
        },
        "RLPilot.Policy.Beta.mean": {
            "value": 0.0020000000000000005,
            "min": 0.002,
            "max": 0.0020000000000000005,
            "count": 31
        },
        "RLPilot.Policy.Beta.sum": {
            "value": 0.004000000000000001,
            "min": 0.002,
            "max": 0.004000000000000001,
            "count": 31
        },
        "RLPilot.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 31
        },
        "RLPilot.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 31
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1750960205",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\desir\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn ./Configs/PilotAgentSelfPlay_v3.yaml --run-id=SelfPlay_v3 --env=../../TrainingBuild/LightingTest.exe --no-graphics --quality-level=0 --num-envs=8 --time-scale=3 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1750964134"
    },
    "total": 3929.1964260000022,
    "count": 1,
    "self": 5.057361500003026,
    "children": {
        "run_training.setup": {
            "total": 2.027793000001111,
            "count": 1,
            "self": 2.027793000001111
        },
        "TrainerController.start_learning": {
            "total": 3922.111271499998,
            "count": 1,
            "self": 4.104253900484764,
            "children": {
                "TrainerController._reset_env": {
                    "total": 27.93460569999297,
                    "count": 3,
                    "self": 27.93460569999297
                },
                "TrainerController.advance": {
                    "total": 3889.542260599519,
                    "count": 13413,
                    "self": 3.986052699277934,
                    "children": {
                        "env_step": {
                            "total": 2914.884885000567,
                            "count": 13413,
                            "self": 940.7170991012099,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1970.3744898992372,
                                    "count": 70883,
                                    "self": 67.40727720023278,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1902.9672126990044,
                                            "count": 137145,
                                            "self": 1902.9672126990044
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 3.7932960001198808,
                                    "count": 13412,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 31141.58812740021,
                                            "count": 70869,
                                            "is_parallel": true,
                                            "self": 25475.32303940098,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.031889400008367375,
                                                    "count": 25,
                                                    "is_parallel": true,
                                                    "self": 0.010198300034971908,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.021691099973395467,
                                                            "count": 150,
                                                            "is_parallel": true,
                                                            "self": 0.021691099973395467
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 5666.2331985992205,
                                                    "count": 70869,
                                                    "is_parallel": true,
                                                    "self": 39.83481310024945,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 38.28303369831701,
                                                            "count": 70869,
                                                            "is_parallel": true,
                                                            "self": 38.28303369831701
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 5457.819312799875,
                                                            "count": 70869,
                                                            "is_parallel": true,
                                                            "self": 5457.819312799875
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 130.29603900077927,
                                                            "count": 138148,
                                                            "is_parallel": true,
                                                            "self": 45.78486269689165,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 84.51117630388762,
                                                                    "count": 828888,
                                                                    "is_parallel": true,
                                                                    "self": 84.51117630388762
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 970.6713228996741,
                            "count": 13412,
                            "self": 14.431016900241957,
                            "children": {
                                "process_trajectory": {
                                    "total": 190.6826028994401,
                                    "count": 13412,
                                    "self": 189.95545639943884,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.727146500001254,
                                            "count": 1,
                                            "self": 0.727146500001254
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 765.5577030999921,
                                    "count": 54,
                                    "self": 480.14960760021495,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 285.4080954997771,
                                            "count": 1716,
                                            "self": 285.4080954997771
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.7999998312443495e-06,
                    "count": 1,
                    "self": 3.7999998312443495e-06
                },
                "TrainerController._save_models": {
                    "total": 0.5301475000014761,
                    "count": 1,
                    "self": 0.07617710000340594,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.4539703999980702,
                            "count": 1,
                            "self": 0.4539703999980702
                        }
                    }
                }
            }
        }
    }
}