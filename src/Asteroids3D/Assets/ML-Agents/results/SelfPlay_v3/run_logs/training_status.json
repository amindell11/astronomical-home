{
    "arena_size": {
        "lesson_num": 0
    },
    "asteroid_density": {
        "lesson_num": 0
    },
    "RLPilot": {
        "elo": 611.3698479647556,
        "checkpoints": [
            {
                "steps": 1587211,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1587211.onnx",
                "reward": 0.38744550003953604,
                "creation_time": 1751147262.4358003,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1587211.pt"
                ]
            },
            {
                "steps": 1999150,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1999150.onnx",
                "reward": -0.12494589015841484,
                "creation_time": 1751155542.139773,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1999150.pt"
                ]
            },
            {
                "steps": 2453339,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-2453339.onnx",
                "reward": 0.08616133711554787,
                "creation_time": 1751252302.7962742,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-2453339.pt"
                ]
            },
            {
                "steps": 2499635,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-2499635.onnx",
                "reward": 0.15344970929436386,
                "creation_time": 1751614262.9103367,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-2499635.pt"
                ]
            },
            {
                "steps": 2503831,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-2503831.onnx",
                "reward": 0.20630855366055453,
                "creation_time": 1751614283.6516032,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-2503831.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 2503831,
            "file_path": "results\\SelfPlay_v3\\RLPilot.onnx",
            "reward": 0.20630855366055453,
            "creation_time": 1751614283.6516032,
            "auxillary_file_paths": [
                "results\\SelfPlay_v3\\RLPilot\\RLPilot-2503831.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "1.1.0",
        "torch_version": "2.7.1+cpu"
    }
}