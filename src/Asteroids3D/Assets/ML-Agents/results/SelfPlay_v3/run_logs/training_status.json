{
    "arena_size": {
        "lesson_num": 0
    },
    "asteroid_density": {
        "lesson_num": 0
    },
    "RLPilot": {
        "elo": 651.7116609954064,
        "checkpoints": [
            {
                "steps": 1160725,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1160725.onnx",
                "reward": -1.2168578863143922,
                "creation_time": 1750964129.3361914,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1160725.pt"
                ]
            },
            {
                "steps": 1499959,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1499959.onnx",
                "reward": -0.000669850544496016,
                "creation_time": 1751105756.7907345,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1499959.pt"
                ]
            },
            {
                "steps": 1587211,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1587211.onnx",
                "reward": 0.38744550003953604,
                "creation_time": 1751147262.4358003,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1587211.pt"
                ]
            },
            {
                "steps": 1999150,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1999150.onnx",
                "reward": -0.12494589015841484,
                "creation_time": 1751155542.139773,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1999150.pt"
                ]
            },
            {
                "steps": 2453339,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-2453339.onnx",
                "reward": 0.08616133711554787,
                "creation_time": 1751252302.7962742,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-2453339.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 2453339,
            "file_path": "results\\SelfPlay_v3\\RLPilot.onnx",
            "reward": 0.08616133711554787,
            "creation_time": 1751252302.7962742,
            "auxillary_file_paths": [
                "results\\SelfPlay_v3\\RLPilot\\RLPilot-2453339.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "1.1.0",
        "torch_version": "2.7.1+cpu"
    }
}