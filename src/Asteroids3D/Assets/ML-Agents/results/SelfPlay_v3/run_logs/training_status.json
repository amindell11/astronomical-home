{
    "arena_size": {
        "lesson_num": 0
    },
    "asteroid_density": {
        "lesson_num": 0
    },
    "RLPilot": {
        "elo": 980.4785262177079,
        "checkpoints": [
            {
                "steps": 123476,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-123476.onnx",
                "reward": -0.5293335430324078,
                "creation_time": 1750957366.3880565,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-123476.pt"
                ]
            },
            {
                "steps": 499045,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-499045.onnx",
                "reward": -0.3747262018067496,
                "creation_time": 1750959218.240117,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-499045.pt"
                ]
            },
            {
                "steps": 544551,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-544551.onnx",
                "reward": -0.5355474948883057,
                "creation_time": 1750959866.16607,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-544551.pt"
                ]
            },
            {
                "steps": 999766,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-999766.onnx",
                "reward": -0.7953097820281982,
                "creation_time": 1750962779.5838346,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-999766.pt"
                ]
            },
            {
                "steps": 1160725,
                "file_path": "results\\SelfPlay_v3\\RLPilot\\RLPilot-1160725.onnx",
                "reward": -1.2168578863143922,
                "creation_time": 1750964129.3361914,
                "auxillary_file_paths": [
                    "results\\SelfPlay_v3\\RLPilot\\RLPilot-1160725.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 1160725,
            "file_path": "results\\SelfPlay_v3\\RLPilot.onnx",
            "reward": -1.2168578863143922,
            "creation_time": 1750964129.3361914,
            "auxillary_file_paths": [
                "results\\SelfPlay_v3\\RLPilot\\RLPilot-1160725.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "1.1.0",
        "torch_version": "2.7.1+cpu"
    }
}